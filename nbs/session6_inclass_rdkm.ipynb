{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 6 - Benchmark classification on ```cifar-10```\n",
    "\n",
    "This notebook builds on what we were doing last week with the handwritten digits from the MNIST dataset.\n",
    "\n",
    "This week, we're working with another famous dataset in computer vision and image processing research - [cifar10](https://www.cs.toronto.edu/~kriz/cifar.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9884bc23",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- cifar-10 dataset = consists of 60 000 images. 10 classes. 32x32 pixel. Colour images. \n",
    "- test batch contains 1000 randomly selected images \n",
    "- train batch contains 5000 images.\n",
    "\n",
    "\n",
    "- Tenserlow is better than scikit learn. \n",
    "- Today we are only using it to load the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# path tools\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# data loader\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# machine learning tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# classificatio models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7343d4b5",
   "metadata": {},
   "source": [
    "We're going to load the data using a function from the library ```TensorFlow```, which we'll be looking at in more detail next week. \n",
    "\n",
    "For now, we're just using it to fetch the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data() # .load_data \n",
    "# returns 4 objects \n",
    "# () groups them together. \n",
    "# Creating a tuple. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b588be73",
   "metadata": {},
   "source": [
    "**Question:** What is the shape of the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "# first number = amount of pictures \n",
    "# Second number =32 by 32\n",
    "# 3rd number = 32 by 32\n",
    "# 4th number  = colour channels."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd02fcbe",
   "metadata": {},
   "source": [
    "Unfortunately, this version of the data set doesn't have explict labels, so we need to create our own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the current labels are just numbers from 1-9\n",
    "labels = [\"airplane\", \n",
    "          \"automobile\", \n",
    "          \"bird\", \n",
    "          \"cat\", \n",
    "          \"deer\", \n",
    "          \"dog\", \n",
    "          \"frog\", \n",
    "          \"horse\", \n",
    "          \"ship\", \n",
    "          \"truck\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert all the data to greyscale"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f5391f3",
   "metadata": {},
   "source": [
    "In the following cell, I'm converting all of my images to greyscale and then making a ```numpy``` array at the end.\n",
    "\n",
    "Notice that I'm using something funky here called *[list comprehensions](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions)*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9376e36b",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- List comprehensions = creating a for loop in a single line. \n",
    "- Syntax of for loop = __for x in y do this(x)__\n",
    "- Syntax for list comprehension = __[do this(x) for x in y]__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_grey = np.array([cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in X_train])\n",
    "X_test_grey = np.array([cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in X_test])\n",
    "# Using opencvs colour conversion model \n",
    "# Create a np.array which is made from the list we make when converging images to grey scale for every image in X_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9703dbdc",
   "metadata": {},
   "source": [
    "Then, we're going to do some simple scaling by dividing by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_scaled = (X_train_grey)/255.0\n",
    "X_test_scaled = (X_test_grey)/255.0\n",
    "# Scaling numbers down to between 0-1\n",
    "# Makes the weights the model has to learn easier/smaller \n",
    "# dividing all pixel values (colours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c141a5e2",
   "metadata": {},
   "source": [
    "Next, we're going to reshape this data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#numpy reshape \n",
    "# from X_train_scaled.shape gets 3 numbers\n",
    "# nsamples = 50 000\n",
    "# nx & ny = 32\n",
    "nsamples, nx, ny = X_train_scaled.shape\n",
    "# new shape to be two values, 50 000 and 1024 (32 times 32)  \n",
    "X_train_dataset = X_train_scaled.reshape((nsamples,nx*ny))\n",
    "\n",
    "# almost the same as numpy flatten function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_test_scaled.shape\n",
    "X_test_dataset = X_test_scaled.reshape((nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple logistic regression classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15bdea84",
   "metadata": {},
   "source": [
    "We define our Logistic Regression classifier as we have done previously. You'll notice that I've set a lot of different parameters here - you can learn more in the documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coder/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/home/coder/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, change: 1.00000000\n",
      "Epoch 2, change: 0.28085799\n",
      "Epoch 3, change: 0.13340751\n",
      "convergence after 4 epochs took 10 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.2s finished\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(penalty=\"none\", # Math about logistic regression. Dont use any penalty values. Use all weights \n",
    "# When penaly is set to l1 = if a value is very small set it to zero. Keeping only meaningful weights \n",
    "                        tol=0.1, # by how much weights should be changing. if not changing by this much then just the training. If the model is not improving by this much then just stop\n",
    "                        verbose=True, # Print an output about model preformance. \n",
    "                        solver=\"saga\", # multiclass dataset \n",
    "                        multi_class=\"multinomial\").fit(X_train_dataset, y_train) # multiclass problem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc10cdb4",
   "metadata": {},
   "source": [
    "We can then print our classification report, using the label names that we defined earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dffab6c",
   "metadata": {},
   "source": [
    "## Notes \n",
    "- use a logistc reg to set a benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.37      0.35      0.36      1000\n",
      "  automobile       0.38      0.33      0.35      1000\n",
      "        bird       0.28      0.18      0.22      1000\n",
      "         cat       0.23      0.14      0.18      1000\n",
      "        deer       0.25      0.19      0.22      1000\n",
      "         dog       0.29      0.31      0.30      1000\n",
      "        frog       0.29      0.32      0.30      1000\n",
      "       horse       0.32      0.31      0.32      1000\n",
      "        ship       0.31      0.49      0.38      1000\n",
      "       truck       0.35      0.51      0.42      1000\n",
      "\n",
      "    accuracy                           0.31     10000\n",
      "   macro avg       0.31      0.31      0.30     10000\n",
      "weighted avg       0.31      0.31      0.30     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, \n",
    "                               y_pred, \n",
    "                               target_names=labels) # setting labels \n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79f6d9b4",
   "metadata": {},
   "source": [
    "I've set a couple of different parameters here - you can see more in the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html).\n",
    "\n",
    "**NB!** This will take a long time to run! On the 32 CPU machine on UCloud, this takes around 30 seconds per iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coder/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.18081081\n",
      "Validation score: 0.230200\n",
      "Iteration 2, loss = 2.03512719\n",
      "Validation score: 0.285000\n",
      "Iteration 3, loss = 1.96959989\n",
      "Validation score: 0.277400\n",
      "Iteration 4, loss = 1.93144341\n",
      "Validation score: 0.313000\n",
      "Iteration 5, loss = 1.89991063\n",
      "Validation score: 0.318000\n",
      "Iteration 6, loss = 1.86922342\n",
      "Validation score: 0.334000\n",
      "Iteration 7, loss = 1.84902258\n",
      "Validation score: 0.340000\n",
      "Iteration 8, loss = 1.82470768\n",
      "Validation score: 0.340600\n",
      "Iteration 9, loss = 1.80246310\n",
      "Validation score: 0.347600\n",
      "Iteration 10, loss = 1.78740588\n",
      "Validation score: 0.353000\n",
      "Iteration 11, loss = 1.77777913\n",
      "Validation score: 0.353200\n",
      "Iteration 12, loss = 1.75619007\n",
      "Validation score: 0.360800\n",
      "Iteration 13, loss = 1.74167545\n",
      "Validation score: 0.368000\n",
      "Iteration 14, loss = 1.73132602\n",
      "Validation score: 0.373400\n",
      "Iteration 15, loss = 1.71718153\n",
      "Validation score: 0.372400\n",
      "Iteration 16, loss = 1.70771119\n",
      "Validation score: 0.374600\n",
      "Iteration 17, loss = 1.69674908\n",
      "Validation score: 0.381800\n",
      "Iteration 18, loss = 1.68782656\n",
      "Validation score: 0.377800\n",
      "Iteration 19, loss = 1.67950203\n",
      "Validation score: 0.388200\n",
      "Iteration 20, loss = 1.66514975\n",
      "Validation score: 0.388200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coder/.local/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(random_state=42, \n",
    "                    hidden_layer_sizes=(100, 10), #hidden layers, everytime it goes from one layer to another and a weight changes it goes back and starts agian.\n",
    "                    learning_rate=\"adaptive\", # beginning of the model it will just be guessing. we want it to learn quickly. as soon as it learns a bit, we get it to slow down, and think more about how to predict.\n",
    "                    early_stopping=True, # Stop early if it is not getting better scores. you can change it by chaning tollerance level\n",
    "                    verbose=True,\n",
    "                    max_iter=20).fit(X_train_dataset, y_train) # max iteratoin of 20 times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddf779a",
   "metadata": {},
   "source": [
    "## Notes \n",
    "- Iteration x, loss = number == should be going down pr iteration to show the model is improving.\n",
    "- Validation score = see how the model compares vs som validation data with the correct answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e489977e",
   "metadata": {},
   "source": [
    "Lastly, we can get our classification report as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.49      0.30      0.37      1000\n",
      "  automobile       0.46      0.50      0.48      1000\n",
      "        bird       0.30      0.23      0.26      1000\n",
      "         cat       0.28      0.20      0.23      1000\n",
      "        deer       0.31      0.32      0.31      1000\n",
      "         dog       0.37      0.36      0.36      1000\n",
      "        frog       0.35      0.48      0.40      1000\n",
      "       horse       0.44      0.46      0.45      1000\n",
      "        ship       0.42      0.60      0.49      1000\n",
      "       truck       0.45      0.44      0.45      1000\n",
      "\n",
      "    accuracy                           0.39     10000\n",
      "   macro avg       0.39      0.39      0.38     10000\n",
      "weighted avg       0.39      0.39      0.38     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, \n",
    "                               y_pred, \n",
    "                               target_names=labels)\n",
    "print(report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a5067ab",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "Take the code outlined in this notebook and turn it into two separate Python scripts, one which performs Logistic Regression classification and one which uses the MLPClassifier on the ```Cifar10``` dataset.\n",
    "\n",
    "Try to use the things we've spoken about in clas\n",
    "- Requirements.txt\n",
    "- Virtual environment\n",
    "- Setup scripts\n",
    "- Argparse\n",
    "\n",
    "This task is [Assignment 2 for Visual Analytics](https://classroom.github.com/a/KLVvny7d)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
